{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2034c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "STOP_WORDS = list(ENGLISH_STOP_WORDS)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors as mcolors, cm, lines as mlines\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from scipy.sparse import lil_matrix, csr_matrix, hstack, vstack\n",
    "\n",
    "import networkx as nx\n",
    "from sknetwork.clustering import Leiden\n",
    "\n",
    "#!pip install google-generativeai httpx\n",
    "import google.generativeai as genai\n",
    "import httpx\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8c6bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "with open('data/amazon_reviews_with_embeddings_and_sentiment.pkl', 'rb') as f:\n",
    "    amazon = pickle.load(f)\n",
    "print(type(amazon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97901416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>embedding</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>2D_embeddings</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perfect Mantra I've been looking for this mant...</td>\n",
       "      <td>1</td>\n",
       "      <td>Perfect Mantra I've been looking for this mant...</td>\n",
       "      <td>[0.028224848210811615, 0.03228772059082985, -0...</td>\n",
       "      <td>{'Very Positive': 0.6087847948074341, 'Positiv...</td>\n",
       "      <td>0.878487</td>\n",
       "      <td>[-2.2331846, 6.180949]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3138719003283342, 0.0677317084709766, 0.179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quality I'm just a little disapointed with the...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quality I'm just a little disapointed with the...</td>\n",
       "      <td>[0.025785230100154877, -0.010898678563535213, ...</td>\n",
       "      <td>{'Negative': 0.5796696543693542, 'Neutral': 0....</td>\n",
       "      <td>-0.517629</td>\n",
       "      <td>[0.86983263, 10.463978]</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.04463512527283897, 0.17382948287054564, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exceptional murder-mystery writer scores big. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Exceptional murder-mystery writer scores big. ...</td>\n",
       "      <td>[0.012370972894132137, 0.03619104251265526, -0...</td>\n",
       "      <td>{'Very Positive': 0.4494209885597229, 'Positiv...</td>\n",
       "      <td>0.858294</td>\n",
       "      <td>[-3.6821277, 6.0072913]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0014503532935837857, 0.03718678093448527, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all the prodding questions you never wanted to...</td>\n",
       "      <td>1</td>\n",
       "      <td>all the prodding questions you never wanted to...</td>\n",
       "      <td>[-0.001434302655979991, 0.027779487892985344, ...</td>\n",
       "      <td>{'Very Positive': 0.6956683993339539, 'Positiv...</td>\n",
       "      <td>0.831368</td>\n",
       "      <td>[-2.8234124, 5.5528483]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.709769771673625, 0.00414207689491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Wok ever I am so glad I bought this wok. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Wok ever I am so glad I bought this wok. ...</td>\n",
       "      <td>[-0.0065714335069060326, -0.06777285784482956,...</td>\n",
       "      <td>{'Very Positive': 0.792975127696991, 'Positive...</td>\n",
       "      <td>0.891844</td>\n",
       "      <td>[2.9735239, 10.172374]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005072706647455209, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Perfect Mantra I've been looking for this mant...      1   \n",
       "1  Quality I'm just a little disapointed with the...      1   \n",
       "2  Exceptional murder-mystery writer scores big. ...      1   \n",
       "3  all the prodding questions you never wanted to...      1   \n",
       "4  Best Wok ever I am so glad I bought this wok. ...      1   \n",
       "\n",
       "                                            document  \\\n",
       "0  Perfect Mantra I've been looking for this mant...   \n",
       "1  Quality I'm just a little disapointed with the...   \n",
       "2  Exceptional murder-mystery writer scores big. ...   \n",
       "3  all the prodding questions you never wanted to...   \n",
       "4  Best Wok ever I am so glad I bought this wok. ...   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.028224848210811615, 0.03228772059082985, -0...   \n",
       "1  [0.025785230100154877, -0.010898678563535213, ...   \n",
       "2  [0.012370972894132137, 0.03619104251265526, -0...   \n",
       "3  [-0.001434302655979991, 0.027779487892985344, ...   \n",
       "4  [-0.0065714335069060326, -0.06777285784482956,...   \n",
       "\n",
       "                                           sentiment  polarity  \\\n",
       "0  {'Very Positive': 0.6087847948074341, 'Positiv...  0.878487   \n",
       "1  {'Negative': 0.5796696543693542, 'Neutral': 0.... -0.517629   \n",
       "2  {'Very Positive': 0.4494209885597229, 'Positiv...  0.858294   \n",
       "3  {'Very Positive': 0.6956683993339539, 'Positiv...  0.831368   \n",
       "4  {'Very Positive': 0.792975127696991, 'Positive...  0.891844   \n",
       "\n",
       "             2D_embeddings  cluster  \\\n",
       "0   [-2.2331846, 6.180949]        0   \n",
       "1  [0.86983263, 10.463978]        8   \n",
       "2  [-3.6821277, 6.0072913]        2   \n",
       "3  [-2.8234124, 5.5528483]        2   \n",
       "4   [2.9735239, 10.172374]        6   \n",
       "\n",
       "                                       cluster_probs  \n",
       "0  [0.3138719003283342, 0.0677317084709766, 0.179...  \n",
       "1  [0.04463512527283897, 0.17382948287054564, 0.0...  \n",
       "2  [0.0014503532935837857, 0.03718678093448527, 0...  \n",
       "3  [0.0, 0.0, 0.709769771673625, 0.00414207689491...  \n",
       "4  [0.0, 0.0, 0.0, 0.005072706647455209, 0.0, 0.0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(amazon.shape)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60a258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(14, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Count</th>\n",
       "      <th>Top_Words</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>2D_Centroid</th>\n",
       "      <th>Top_Representative_Docs</th>\n",
       "      <th>Top_Words_TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>{'album': 659, 'cd': 617, 'great': 393, 'music...</td>\n",
       "      <td>0.623137</td>\n",
       "      <td>[0.011593475740294592, -0.009051741308382663, ...</td>\n",
       "      <td>[-6.3378177, 11.714415]</td>\n",
       "      <td>[A Great CD!! I just brouth the cd DATE and i ...</td>\n",
       "      <td>{'cd': 0.4524236413718734, 'album': 0.18096945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>691</td>\n",
       "      <td>{'movie': 665, 'great': 324, 'film': 251, 'goo...</td>\n",
       "      <td>0.560485</td>\n",
       "      <td>[0.0028552300495080555, 0.028399670222276224, ...</td>\n",
       "      <td>[-3.3686092, 8.544506]</td>\n",
       "      <td>[ORGANIZATION This is a great family movie. My...</td>\n",
       "      <td>{'movie': 0.2605772667341845, 'location': 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1073</td>\n",
       "      <td>{'book': 1618, 'read': 774, 'location': 479, '...</td>\n",
       "      <td>0.613922</td>\n",
       "      <td>[0.008959872890230298, 0.02307058386564865, -0...</td>\n",
       "      <td>[-3.1564274, 6.083331]</td>\n",
       "      <td>[Awesome story! I read this book DATE and was ...</td>\n",
       "      <td>{'book': 0.5235569991369154, 'read': 0.2966822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>398</td>\n",
       "      <td>{'great': 244, 'good': 163, 'use': 149, 'produ...</td>\n",
       "      <td>0.495964</td>\n",
       "      <td>[0.0005142235821762343, -0.009841657266474955,...</td>\n",
       "      <td>[1.3146882, 11.555882]</td>\n",
       "      <td>[pretty decent Love it, wireless works a lil f...</td>\n",
       "      <td>{'great': 0.2819436353692122, 'works': 0.13012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>{'book': 196, 'read': 93, 'good': 51, 'story':...</td>\n",
       "      <td>0.305131</td>\n",
       "      <td>[0.0037351046676200855, 0.03597368089299973, -...</td>\n",
       "      <td>[-3.7777233, 5.4500985]</td>\n",
       "      <td>[Sad to see all of these one-star ratings I th...</td>\n",
       "      <td>{'book': 0.39259818498534416, 'read': 0.215929...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Count                                          Top_Words  \\\n",
       "0        0    898  {'album': 659, 'cd': 617, 'great': 393, 'music...   \n",
       "1        1    691  {'movie': 665, 'great': 324, 'film': 251, 'goo...   \n",
       "2        2   1073  {'book': 1618, 'read': 774, 'location': 479, '...   \n",
       "3        3    398  {'great': 244, 'good': 163, 'use': 149, 'produ...   \n",
       "4        4    115  {'book': 196, 'read': 93, 'good': 51, 'story':...   \n",
       "\n",
       "   Polarity                                           Centroid  \\\n",
       "0  0.623137  [0.011593475740294592, -0.009051741308382663, ...   \n",
       "1  0.560485  [0.0028552300495080555, 0.028399670222276224, ...   \n",
       "2  0.613922  [0.008959872890230298, 0.02307058386564865, -0...   \n",
       "3  0.495964  [0.0005142235821762343, -0.009841657266474955,...   \n",
       "4  0.305131  [0.0037351046676200855, 0.03597368089299973, -...   \n",
       "\n",
       "               2D_Centroid                            Top_Representative_Docs  \\\n",
       "0  [-6.3378177, 11.714415]  [A Great CD!! I just brouth the cd DATE and i ...   \n",
       "1   [-3.3686092, 8.544506]  [ORGANIZATION This is a great family movie. My...   \n",
       "2   [-3.1564274, 6.083331]  [Awesome story! I read this book DATE and was ...   \n",
       "3   [1.3146882, 11.555882]  [pretty decent Love it, wireless works a lil f...   \n",
       "4  [-3.7777233, 5.4500985]  [Sad to see all of these one-star ratings I th...   \n",
       "\n",
       "                                     Top_Words_TFIDF  \n",
       "0  {'cd': 0.4524236413718734, 'album': 0.18096945...  \n",
       "1  {'movie': 0.2605772667341845, 'location': 0.20...  \n",
       "2  {'book': 0.5235569991369154, 'read': 0.2966822...  \n",
       "3  {'great': 0.2819436353692122, 'works': 0.13012...  \n",
       "4  {'book': 0.39259818498534416, 'read': 0.215929...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/cluster_info_A_amazon.pkl', 'rb') as f:\n",
    "    amazon_A = pickle.load(f)\n",
    "print(type(amazon_A))\n",
    "print(amazon_A.shape)\n",
    "amazon_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816261f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(14, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Count</th>\n",
       "      <th>Top_Words</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>2D_Centroid</th>\n",
       "      <th>Top_Representative_Docs</th>\n",
       "      <th>Top_Words_TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>{'cd': 306, 'album': 295, 'like': 278, 'music'...</td>\n",
       "      <td>-0.320870</td>\n",
       "      <td>[0.005391814288830293, 0.00656481949659372, -0...</td>\n",
       "      <td>[-5.6849732, 11.980106]</td>\n",
       "      <td>[NUM well crafted songs does NOT make a great ...</td>\n",
       "      <td>{'cd': 0.3029982081186027, 'just': 0.196057664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>692</td>\n",
       "      <td>{'movie': 868, 'film': 305, 'like': 244, 'just...</td>\n",
       "      <td>-0.410263</td>\n",
       "      <td>[-0.010680105894241518, 0.04162282063466355, -...</td>\n",
       "      <td>[-3.8498094, 9.028647]</td>\n",
       "      <td>[What the hell did I just watch. I am a true B...</td>\n",
       "      <td>{'movie': 0.3745573527068864, 'didn': 0.138533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>{'book': 184, 'location': 109, 'read': 60, 'ju...</td>\n",
       "      <td>-0.056081</td>\n",
       "      <td>[0.004660180020229225, 0.03213820015807869, -0...</td>\n",
       "      <td>[-3.2405305, 5.507901]</td>\n",
       "      <td>[Once again, Russo spreads lies to make a quic...</td>\n",
       "      <td>{'book': 0.40700837223395525, 'location': 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>738</td>\n",
       "      <td>{'product': 274, 'work': 262, 'buy': 187, 'jus...</td>\n",
       "      <td>-0.441048</td>\n",
       "      <td>[-0.012323810111746356, 0.007264140421755306, ...</td>\n",
       "      <td>[1.3935039, 11.628746]</td>\n",
       "      <td>[Won't stand by warranty ORGANIZATION shopping...</td>\n",
       "      <td>{'unit': 0.2459720427620044, 'product': 0.1892...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>835</td>\n",
       "      <td>{'book': 1418, 'read': 540, 'just': 301, 'like...</td>\n",
       "      <td>-0.421902</td>\n",
       "      <td>[0.0019212170836502894, 0.04200785495278957, -...</td>\n",
       "      <td>[-3.8869593, 5.000855]</td>\n",
       "      <td>[Very Disappointing I'm not sure where to star...</td>\n",
       "      <td>{'book': 0.49640651618480125, 'read': 0.215109...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Count                                          Top_Words  \\\n",
       "0        0    511  {'cd': 306, 'album': 295, 'like': 278, 'music'...   \n",
       "1        1    692  {'movie': 868, 'film': 305, 'like': 244, 'just...   \n",
       "2        2    140  {'book': 184, 'location': 109, 'read': 60, 'ju...   \n",
       "3        3    738  {'product': 274, 'work': 262, 'buy': 187, 'jus...   \n",
       "4        4    835  {'book': 1418, 'read': 540, 'just': 301, 'like...   \n",
       "\n",
       "   Polarity                                           Centroid  \\\n",
       "0 -0.320870  [0.005391814288830293, 0.00656481949659372, -0...   \n",
       "1 -0.410263  [-0.010680105894241518, 0.04162282063466355, -...   \n",
       "2 -0.056081  [0.004660180020229225, 0.03213820015807869, -0...   \n",
       "3 -0.441048  [-0.012323810111746356, 0.007264140421755306, ...   \n",
       "4 -0.421902  [0.0019212170836502894, 0.04200785495278957, -...   \n",
       "\n",
       "               2D_Centroid                            Top_Representative_Docs  \\\n",
       "0  [-5.6849732, 11.980106]  [NUM well crafted songs does NOT make a great ...   \n",
       "1   [-3.8498094, 9.028647]  [What the hell did I just watch. I am a true B...   \n",
       "2   [-3.2405305, 5.507901]  [Once again, Russo spreads lies to make a quic...   \n",
       "3   [1.3935039, 11.628746]  [Won't stand by warranty ORGANIZATION shopping...   \n",
       "4   [-3.8869593, 5.000855]  [Very Disappointing I'm not sure where to star...   \n",
       "\n",
       "                                     Top_Words_TFIDF  \n",
       "0  {'cd': 0.3029982081186027, 'just': 0.196057664...  \n",
       "1  {'movie': 0.3745573527068864, 'didn': 0.138533...  \n",
       "2  {'book': 0.40700837223395525, 'location': 0.23...  \n",
       "3  {'unit': 0.2459720427620044, 'product': 0.1892...  \n",
       "4  {'book': 0.49640651618480125, 'read': 0.215109...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/cluster_info_B_amazon.pkl', 'rb') as f:\n",
    "    amazon_B = pickle.load(f)\n",
    "print(type(amazon_B))\n",
    "print(amazon_B.shape)\n",
    "amazon_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2836fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative_dimensions = [\n",
    "    \"Economic growth – Economic decline\",\n",
    "    \"Financial stability – Financial instability\",\n",
    "    \"Innovation – Tradition\",\n",
    "    \"Market confidence – Market anxiety\",\n",
    "    \"Risk-taking – Risk aversion\",\n",
    "    \"Technological optimism – Technological skepticism\",\n",
    "    \"Environmental responsibility – Environmental negligence\",\n",
    "    \"Public health focus – Economic focus\",\n",
    "    \"Consumer empowerment – Consumer manipulation\",\n",
    "    \"Globalization – Nationalism\",\n",
    "    \"Regulation – Deregulation\",\n",
    "    \"Competition – Monopoly\",\n",
    "    \"Efficiency – Redundancy\",\n",
    "    \"Productivity – Laziness\",\n",
    "    \"Sustainability – Exploitation\",\n",
    "    \"Scalability – Inflexibility\",\n",
    "    \"Inclusivity – Exclusivity\",\n",
    "    \"Transparency – Obfuscation\",\n",
    "    \"Accountability – Irresponsibility\",\n",
    "    \"Safety – Danger\",\n",
    "    \"Collaboration – Isolation\",\n",
    "    \"Accessibility – Elitism\",\n",
    "    \"Long-term thinking – Short-term thinking\",\n",
    "    \"Innovation – Stagnation\",\n",
    "    \n",
    "    # Moral & Ethical\n",
    "    \"Justice – Injustice\",\n",
    "    \"Equity – Inequity\",\n",
    "    \"Honesty – Deception\",\n",
    "    \"Integrity – Corruption\",\n",
    "    \"Altruism – Self-interest\",\n",
    "    \"Responsibility – Negligence\",\n",
    "    \"Loyalty – Betrayal\",\n",
    "    \"Consent – Coercion\",\n",
    "    \"Fairness – Bias\",\n",
    "    \"Empathy – Apathy\",\n",
    "    \"Gratitude – Entitlement\",\n",
    "    \"Generosity – Greed\",\n",
    "    \"Respect – Disregard\",\n",
    "    \"Forgiveness – Vengeance\",\n",
    "    \"Courage – Cowardice\",\n",
    "    \"Authenticity – Hypocrisy\",\n",
    "    \n",
    "    # Social & Interpersonal\n",
    "    \"Authority – Rebellion\",\n",
    "    \"Agreement – Disagreement\",\n",
    "    \"Politeness – Rudeness\",\n",
    "    \"Assertiveness – Passivity\",\n",
    "    \"Consensus – Polarization\",\n",
    "    \"Trust – Distrust\",\n",
    "    \"Leadership – Subordination\",\n",
    "    \"Support – Opposition\",\n",
    "    \"Closeness – Distance\",\n",
    "    \"Mentorship – Criticism\",\n",
    "    \"Professionalism – Informality\",\n",
    "    \"Respect – Dismissiveness\",\n",
    "    \n",
    "    # Emotional & Psychological\n",
    "    \"Optimism – Pessimism\",\n",
    "    \"Excitement – Boredom\",\n",
    "    \"Confidence – Doubt\",\n",
    "    \"Calm – Anxiety\",\n",
    "    \"Hope – Despair\",\n",
    "    \"Happiness – Sadness\",\n",
    "    \"Empowerment – Helplessness\",\n",
    "    \"Passion – Indifference\",\n",
    "    \"Resilience – Fragility\",\n",
    "    \"Fulfillment – Frustration\",\n",
    "    \"Enthusiasm – Apathy\",\n",
    "    \"Pride – Shame\",\n",
    "    \"Joy – Grief\",\n",
    "    \"Motivation – Complacency\",\n",
    "    \"Curiosity – Disinterest\",\n",
    "    \"Satisfaction – Disappointment\",\n",
    "    \n",
    "    # Tone & Style\n",
    "    \"Formal – Informal\",\n",
    "    \"Objective – Subjective\",\n",
    "    \"Concise – Wordy\",\n",
    "    \"Direct – Indirect\",\n",
    "    \"Sincere – Sarcastic\",\n",
    "    \"Serious – Humorous\",\n",
    "    \"Persuasive – Descriptive\",\n",
    "    \"Analytical – Narrative\",\n",
    "    \"Technical – Layperson-friendly\",\n",
    "    \"Measured – Exaggerated\",\n",
    "    \"Assertive – Tentative\",\n",
    "    \"Friendly – Hostile\",\n",
    "    \n",
    "    # Intent & Function\n",
    "    \"Persuasion – Information\",\n",
    "    \"Promotion – Critique\",\n",
    "    \"Instruction – Storytelling\",\n",
    "    \"Reporting – Speculating\",\n",
    "    \"Defending – Attacking\",\n",
    "    \"Clarification – Confusion\",\n",
    "    \"Invitation – Rejection\",\n",
    "    \"Compliance – Resistance\",\n",
    "    \"Escalation – De-escalation\",\n",
    "    \"Problem framing – Solution framing\",\n",
    "    \"Root cause analysis – Symptom description\",\n",
    "    \"Innovation proposal – Status quo defense\",\n",
    "    \"Apology – Justification\",\n",
    "    \"Advocacy – Observation\",\n",
    "    \n",
    "    # Perspective & Framing\n",
    "    \"First-person – Third-person\",\n",
    "    \"Subjective – Objective\",\n",
    "    \"Quantitative – Qualitative\",\n",
    "    \"Macro – Micro\",\n",
    "    \"Local – Global\",\n",
    "    \"Personal – Institutional\",\n",
    "    \"Insider – Outsider\",\n",
    "    \"Predictive – Retrospective\",\n",
    "    \"Static – Dynamic\",\n",
    "    \"Present-focused – Future-focused\",\n",
    "    \n",
    "    # Academic & Scientific Style\n",
    "    \"Evidence-based – Anecdotal\",\n",
    "    \"Theoretical – Empirical\",\n",
    "    \"Precise – Ambiguous\",\n",
    "    \"Cautious – Bold\",\n",
    "    \"Methodological – Exploratory\",\n",
    "    \"Hypothesis-driven – Observation-driven\",\n",
    "    \"Peer-oriented – Public-oriented\",\n",
    "    \"Originality – Replication\",\n",
    "    \"Novelty – Confirmation\",\n",
    "    \"Scientific neutrality – Advocacy\",\n",
    "    \n",
    "    # Consumer & Review\n",
    "    \"Value for money – Overpriced\",\n",
    "    \"User-friendly – Complicated\",\n",
    "    \"High quality – Poor quality\",\n",
    "    \"Responsive – Unresponsive\",\n",
    "    \"Durable – Fragile\",\n",
    "    \"Reliable – Buggy\",\n",
    "    \"Trustworthy – Misleading\",\n",
    "    \"Helpful – Unhelpful\",\n",
    "    \"Recommended – Not recommended\"\n",
    "]\n",
    "dimension_list_str = \"\\n\".join(narrative_dimensions)\n",
    "with open(\"out/narrative_dimensions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dimension_list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2186087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_narrative_comparison_prompt(text1, text2):\n",
    "    prompt_template = f\"\"\"\n",
    "Role: You are a narrative analyst specialist in identifying all semantic perspectives in texts, so called narrative dimensions.\n",
    "Task: Identify and compare all narrative dimensions present in the texts \"text1\" and \"text2\".\n",
    "\n",
    "Narrative dimensions are fine-grained semantic elements that capture contrasts in topic, subtopic, perspective, intention, nuance, morality, emotion, sentiment, personality, intensity, solution/problem framing, accountability, or other discourse-level distinctions.\n",
    "Use the list of dimensions below as inspiration, allow the emergence of any new one, be creative and open. Only output JSON as specified.\n",
    "\n",
    "--- Dimensions ---\n",
    "{dimension_list_str}\n",
    "\n",
    "For each narrative dimension, follow this output format:\n",
    "- Title: A short phrase that captures the main contrast.\n",
    "- Subtitle: The two poles of the dimension (e.g., financial stability – financial instability).\n",
    "- Presence: Indicate whether it appears in text1 only, text2 only, or both.\n",
    "- Coverage: Percentage (0–100%) indicating how much of each text is devoted to this dimension. Together, the dimensions should account for 100% of each text. Zero coverage is allowed for one text, but not both.\n",
    "- Perspective Shift: Estimate the directional change between texts as a percentage (0–100%).\n",
    "- Cosine Similarity: Indicate the cosine similarity (from –1 to 1) between the text representations for this dimension.\n",
    "- Evidence: Quote at least 2–3 representative sentences from each text that reflect each pole.\n",
    "\n",
    "Example Output Format:\n",
    "\n",
    "Dimension: Financial stability  \n",
    "Subtitle: Stability – Instability  \n",
    "Presence: Both  \n",
    "Coverage: text1: 30%, text2: 15%  \n",
    "Perspective Shift: 40%  \n",
    "Cosine Similarity: –0.42  \n",
    "Evidence:  \n",
    "- text1: \n",
    "  • \"The company faces major risks due to market downturn.\"  \n",
    "  • \"Investors are pulling out amid uncertainty.\"  \n",
    "  • \"Revenue has dropped by 20% over the last quarter.\"  \n",
    "- text2: \n",
    "  • \"Recent investments have secured long-term growth.\"  \n",
    "  • \"The financial outlook remains positive, according to the Q2 report.\"  \n",
    "  • \"Diversification strategies have reduced exposure to risk.\"\n",
    "\n",
    "Repeat this for all narrative dimensions needed to fully account for both texts.\n",
    "\n",
    "Output **only** a valid JSON list of objects in this exact format — no additional text, no commentary, no explanations.\n",
    "\n",
    "Example output:\n",
    "[\n",
    "  {{\n",
    "    \"dimension_title\": \"Financial Stability\",\n",
    "    \"polar_extremes_subtitle\": \"Financial instability – Financial stability\",\n",
    "    \"presence\": \"both\",\n",
    "    \"coverage_text1\": 60,\n",
    "    \"coverage_text2\": 40,\n",
    "    \"difference_confidence\": 40,\n",
    "    \"cosine_similarity\": 0.72,\n",
    "    \"text1_evidence_sentences\": [\n",
    "      \"The company is struggling with cash flow.\",\n",
    "      \"Debt levels are increasing rapidly.\",\n",
    "      \"Investors have lost confidence.\"\n",
    "    ],\n",
    "    \"text2_evidence_sentences\": [\n",
    "      \"Strong profit growth is reported.\",\n",
    "      \"Revenue streams are diversifying.\",\n",
    "      \"The market shows consistent recovery.\"\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\n",
    "--- Begin Text Analysis ---\n",
    "\n",
    "text1:\n",
    "{text1}\n",
    "\n",
    "text2:\n",
    "{text2}\n",
    "\"\"\"\n",
    "    return prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc24487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import io\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv() # Load the .env file with API key\n",
    "#genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "#genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAjgfv08Tqt5R4GzjUXDoQUPgFLGxV8u_U\")\n",
    "client = genai.GenerativeModel(\"gemini-2.0-flash\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb39c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "\n",
    "def safe_json_load(raw_response_text):\n",
    "    # Strip leading/trailing whitespace and remove non-JSON \"explanation\" text if any\n",
    "    raw_text = raw_response_text.strip()\n",
    "\n",
    "    # Attempt quick fix: if it starts/ends with JSON brackets\n",
    "    if not raw_text.startswith('[') and '[' in raw_text:\n",
    "        raw_text = raw_text[raw_text.index('['):]\n",
    "    if not raw_text.endswith(']') and ']' in raw_text:\n",
    "        raw_text = raw_text[:raw_text.rindex(']') + 1]\n",
    "\n",
    "    # Remove or escape invalid escape characters\n",
    "    def escape_invalid_escapes(s):\n",
    "        # Fix invalid escape sequences: \\x, \\u (if malformed), or backslashes not part of valid escape\n",
    "        s = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', s)  # Replace lone backslashes\n",
    "        return s\n",
    "\n",
    "    try:\n",
    "        return json.loads(escape_invalid_escapes(raw_text))\n",
    "    except json.JSONDecodeError as e:\n",
    "        try:\n",
    "            # Try ast.literal_eval as fallback (tolerates single quotes, trailing commas)\n",
    "            return ast.literal_eval(raw_text)\n",
    "        except Exception as fallback_error:\n",
    "            print(\"⚠️ JSON parsing failed.\")\n",
    "            print(\"JSON error:\", e)\n",
    "            print(\"Fallback error:\", fallback_error)\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c2722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed and saved row 0\n",
      "✅ Processed and saved row 1\n",
      "✅ Processed and saved row 2\n",
      "✅ Processed and saved row 3\n",
      "✅ Processed and saved row 4\n",
      "✅ Processed and saved row 5\n",
      "✅ Processed and saved row 6\n",
      "✅ Processed and saved row 7\n",
      "✅ Processed and saved row 8\n",
      "✅ Processed and saved row 9\n",
      "✅ Processed and saved row 10\n",
      "✅ Processed and saved row 11\n",
      "✅ Processed and saved row 12\n",
      "✅ Processed and saved row 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(amazon_A)):\n",
    "    text1 = amazon_A['Top_Representative_Docs'].iloc[i]\n",
    "    text2 = amazon_B['Top_Representative_Docs'].iloc[i]\n",
    "\n",
    "    prompt = generate_narrative_comparison_prompt(text1, text2)\n",
    "    response = client.generate_content(prompt)\n",
    "\n",
    "    # Dynamic response variable (you can also use a list or dict instead of naming each one)\n",
    "    var_name = f\"response_row{i}\"\n",
    "    globals()[var_name] = response\n",
    "\n",
    "    # Parse the JSON response safely\n",
    "    parsed_llm_out = safe_json_load(response.text)\n",
    "\n",
    "    # Save to file\n",
    "    with open(f\"out/amazon_ND_row{i}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(parsed_llm_out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Processed and saved row {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_13_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
